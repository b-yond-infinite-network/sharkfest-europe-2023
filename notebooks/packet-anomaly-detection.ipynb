{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WwPf-8fzjT18"
   },
   "source": [
    "# Packet Anomaly detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mlaIoGIecD4l"
   },
   "source": [
    "We used the data set available (sometimes) at the Canadian institute of cybersecurity: https://www.unb.ca/cic/datasets/iotdataset-2022.html\n",
    "\n",
    "This dataset is simulated data from the folowing setup:\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/b-yond-infinite-network/sharkfest-europe-2023/main/assets/iot-setup.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHy32Rx1a5SX"
   },
   "source": [
    "\n",
    "To create chunks from a large PCAP file:\n",
    "\n",
    "\n",
    "```\n",
    "editcap -c [chunk size] [inputfile.pcap]  [outputdir]/[prefix].pcap\n",
    "```\n",
    "\n",
    "**In the following, we fix the chunk size to 10000 Frames.**\n",
    "\n",
    "To extract pcap into a csv file:\n",
    "\n",
    "\n",
    "```\n",
    "tshark -r [file.pcap]  -T fields -e frame.number -e frame.interface_id -e frame.len -e frame.protocols -e frame.time_delta -e ip.hdr_len -e ip.len -e ip.proto -e ip.ttl -e ip.version -E aggregator=\"$\" -E separator=\";\" -E header=y```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify runtime environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pFBNMmygrImA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    # Load the autoreload extension for IPython\n",
    "    %load_ext autoreload\n",
    "    # Set the autoreload extension to reload modules every time they are imported, so that changes made to code in the src folder are reflected in the running code\n",
    "    %autoreload 2\n",
    "    %pip install scikit-learn==1.3.1\n",
    "except:\n",
    "    IN_COLAB = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LxDnL_bY66b",
    "tags": []
   },
   "source": [
    "## Load Data\n",
    "First part is to read the data from the disk. The data has been extracted using `tshark` and stored in a CSV files `extract_active.csv` and `extract_idle.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lK-CKx7kraqz"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df_active = pd.read_csv(\"https://github.com/b-yond-infinite-network/sharkfest-europe-2023-data/raw/main/packet-anomaly-detection/packet-anomaly-detection-data-active.zip\", compression='zip' ,index_col=0)\n",
    "df_idle = pd.read_csv(\"https://github.com/b-yond-infinite-network/sharkfest-europe-2023-data/raw/main/packet-anomaly-detection/packet-anomaly-detection-data-idle.zip\", compression='zip' ,index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_active.info()\n",
    "df_idle.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3D2Rw-yLtF6H"
   },
   "outputs": [],
   "source": [
    "\n",
    "def keep_columns_with_data(df):\n",
    "    return df.loc[:, df.apply(lambda x: x.isnull().sum() != df.shape[0], axis=0)]\n",
    "\n",
    "def encode_protocols(df, colname):\n",
    "    protocols_df = df[colname].str.get_dummies(sep=':')\n",
    "\n",
    "    data_with_protocols = pd.concat([df, protocols_df], axis=1)\n",
    "\n",
    "    return data_with_protocols.drop(colname, axis=1)\n",
    "\n",
    "def create_index(df):\n",
    "    df.index = df.apply(lambda x: f\"{x['file']}\", axis=1)\n",
    "    df.drop(['file', 'frame.number'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def clean_nested(df):\n",
    "    non_numeric_cols = ['ip.hdr_len', 'ip.len', 'ip.proto', 'ip.ttl', 'ip.version']\n",
    "    for col in non_numeric_cols:\n",
    "        df[col] = df[col].apply(lambda x: str(x).split('$')[0])\n",
    "    df[non_numeric_cols] = df[non_numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "    return df\n",
    "\n",
    "def fill_missing_values(df):\n",
    "    df.fillna(-1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def preprocess(df):\n",
    "    res = encode_protocols(df, 'frame.protocols')\n",
    "    res = create_index(res)\n",
    "    res = clean_nested(res)\n",
    "    res = keep_columns_with_data(res)\n",
    "    res = fill_missing_values(res)\n",
    "    return res\n",
    "\n",
    "def create_features(df):\n",
    "    return df.groupby(level=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A-tssgu2yjG2"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df_active = create_features(preprocess(df_active))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hUQ6Qdr2ypS1"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df_idle = create_features(preprocess(df_idle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7zPz6qCw3PCo"
   },
   "outputs": [],
   "source": [
    "df_idle = df_idle.loc[:,df_idle.mean().sort_values()>10]\n",
    "columns = list(set(df_active.columns) & set(df_idle.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZnMhgRFO2CkF"
   },
   "outputs": [],
   "source": [
    "df_active = df_active[columns]\n",
    "df_idle = df_idle[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PXJXI91iFrRQ",
    "outputId": "b19a225e-af95-40b9-ad05-8aaf30f3af32"
   },
   "outputs": [],
   "source": [
    "df_active.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n8DRIT4Z262j"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import train_test_split\n",
    "pos_train, pos_test = train_test_split(df_idle,test_size=0.01)\n",
    "neg_train, neg_test = train_test_split(df_active,test_size=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ks4I2b6k3m1F"
   },
   "outputs": [],
   "source": [
    "train = pd.concat([pos_train])\n",
    "test = pd.concat([pos_test,neg_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w5DUBkMXDSk-"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_train = pd.DataFrame(pca.fit_transform(train))\n",
    "pca_test =  pd.DataFrame(pca.transform(test))\n",
    "train['label'] = len(train)*[1]\n",
    "test['label'] = len(pos_test)*[1]+len(neg_test)*[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vF15oZkXDUs2"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import IsolationForest\n",
    "iforest = IsolationForest(contamination = 0.5,random_state=42)\n",
    "iforest.fit(pca_train)\n",
    "preds_train = iforest.predict(pca_train)\n",
    "preds_test = iforest.predict(pca_test)\n",
    "train['preds'] =  preds_train\n",
    "test['preds'] = preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bsQlPE31DXHL",
    "outputId": "0a41c73a-bba1-4224-cf6c-1ecef1329af9"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(test['label'],test['preds']))\n",
    "print(confusion_matrix(test['label'],test['preds']))\n",
    "print(confusion_matrix(train['label'],train['preds']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 659
    },
    "id": "lo_CYWEtDaeA",
    "outputId": "29b05b81-4204-4a38-a13d-9e97521de501"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Concatenate the datasets\n",
    "# combined_df = pd.concat([train, test])\n",
    "combined_df = pd.concat([ train])\n",
    "\n",
    "# Handle missing values by replacing NaNs with median of each column\n",
    "# combined_df.fillna(combined_df.median(), inplace=True)\n",
    "labels = combined_df['label'].to_list()\n",
    "preds = combined_df['preds'].to_list()\n",
    "combined_df.drop(['label','preds'],axis=1,inplace=True)\n",
    "# Scale the features\n",
    "# scaler = StandardScaler()\n",
    "# data_scaled = scaler.fit_transform(combined_df)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(combined_df)\n",
    "principal_components = pca.transform(combined_df)\n",
    "\n",
    "# Create a DataFrame with the principal components\n",
    "pc_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])\n",
    "pc_df['label'] = labels\n",
    "pc_df['preds'] = preds\n",
    "# Plot the 2D PCA results\n",
    "plt.figure(figsize=(10, 7))\n",
    "colors = {1: 'red', -1: 'blue'}\n",
    "markers = {-1: 'x', 1: '^'}\n",
    "\n",
    "for actual_value, group in pc_df.groupby('label'):\n",
    "    for pred_value, sub_group in group.groupby('preds'):\n",
    "        alpha = 1\n",
    "        color = colors[actual_value]\n",
    "        if pred_value != actual_value:\n",
    "            alpha=1\n",
    "            # color = 'green'\n",
    "        plt.scatter(sub_group['PC1'], sub_group['PC2'], c=color, s=50, marker=markers[pred_value],alpha=alpha)\n",
    "\n",
    "# plt.scatter(pc_df['PC1'], pc_df['PC2'], c=pc_df['label'].map(colors), s=50)\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('2D PCA of Idle vs. Active PCAP Summaries')\n",
    "plt.legend(handles=[plt.Line2D([0], [0], marker='x', color='red', markerfacecolor='red', markersize=10, label='Active, predicted Idle'),\n",
    "    plt.Line2D([0], [0], marker='^', color='red', markerfacecolor='red', markersize=10, label='Active, predicted Active'),\n",
    "    plt.Line2D([0], [0], marker='x', color='blue', markerfacecolor='blue', markersize=10, label='Idle, predicted Idle'),\n",
    "    plt.Line2D([0], [1], marker='^', color='blue', markerfacecolor='blue', markersize=10, label='Idle, predicted Active')\n",
    "    ])\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Compute the explained variance by the two principal components\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "\n",
    "print(explained_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZyfeZ5T6DfDK",
    "outputId": "7b11f3a9-8e4f-4100-e4a9-efcca037928e"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "\n",
    "pc_df_test = pd.DataFrame(pca.transform(test.drop(['preds','label'],axis=1)),columns=['PC1','PC2'])\n",
    "labels = train['label'].to_list(),test['label'].to_list()\n",
    "X = pd.concat([pc_df.drop(['label','preds'],axis=1),pc_df_test])\n",
    "\n",
    "disp = DecisionBoundaryDisplay.from_estimator(\n",
    "    iforest,\n",
    "    X,\n",
    "    response_method=\"decision_function\",\n",
    "    alpha=0.5,\n",
    "\n",
    ")\n",
    "\n",
    "scatter = disp.ax_.scatter(X['PC1'], X['PC2'], c=labels, s=20, edgecolor=\"k\",alpha=0.3)\n",
    "disp.ax_.scatter(pc_df_test['PC1'],pc_df_test['PC2'])\n",
    "disp.ax_.set_title(\"Path length decision boundary \\nof IsolationForest\")\n",
    "# plt.axis(\"square\")\n",
    "handles, _ = scatter.legend_elements()\n",
    "# disp.ax_.set_ylim([-1,1])\n",
    "# plt.legend(handles=handles, labels=[\"outliers\", \"inliers\"], title=\"true class\")\n",
    "plt.colorbar(disp.ax_.collections[1])\n",
    "display(figure())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7KG-m2y_L0uj",
    "outputId": "02a31270-aae9-4f35-fc6b-bdf78ad044ca"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "pc_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nxb3RpD1F77J"
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows= 99999\n",
    "pd.set_option('max_colwidth', 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j39NNMTIG4fT",
    "outputId": "851b4066-72e3-4aeb-8ae4-3b44b1ea043f"
   },
   "outputs": [],
   "source": [
    "len(df_idle.columns[df_idle.mean().sort_values()>3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 626
    },
    "id": "P7WM9XvxHACD",
    "outputId": "215e7f6a-8efa-4743-e820-b754ddadbeac"
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "ax1.hist([df_idle['frame.time_delta'],df_active['frame.time_delta']],bins=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vpc9NPMKHlf8",
    "outputId": "050f5c06-192a-4cc4-c393-6987d15ef4e5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "Y_O4iHfKHXG_",
    "outputId": "61edefcc-50dc-4319-eafa-930836c6089d"
   },
   "outputs": [],
   "source": [
    "df_idle['frame.time_delta'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U2eAN-CfHbPx"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
