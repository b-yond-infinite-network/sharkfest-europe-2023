{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eefcc8cf-3ccd-4ffa-9853-b991159ab88e",
     "showTitle": false,
     "title": ""
    },
    "id": "WwPf-8fzjT18"
   },
   "source": [
    "# Packet Anomaly detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0f3ccb07-c898-422d-be7d-40737511260a",
     "showTitle": false,
     "title": ""
    },
    "id": "mlaIoGIecD4l"
   },
   "source": [
    "We used the data set available (sometimes) at the Canadian institute of cybersecurity: https://www.unb.ca/cic/datasets/iotdataset-2022.html\n",
    "\n",
    "This dataset is simulated data from the folowing setup:\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/b-yond-infinite-network/sharkfest-europe-2023/main/assets/iot-setup.jpg\">\n",
    "\n",
    "We focused on Idle and Active use cases in this experiment as described below:\n",
    "\n",
    "- **Idle**: In this experiment, we captured the whole network traffic from late in the evening to early in the morning, which we call idle time. In this period, the whole lab was completely evacuated and there were no human interactions involved.\n",
    "\n",
    "- **Active**: In addition to the idle time, the whole network communications were also captured throughout the day. All fellow researchers during this period were allowed to enter the lab whenever they wanted. They might interact with devices and generate network traffic either passively or actively.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3999a8a0-de34-45f1-bd9b-50c00e16f878",
     "showTitle": false,
     "title": ""
    },
    "id": "NHy32Rx1a5SX"
   },
   "source": [
    "\n",
    "To create chunks from a large PCAP file:\n",
    "\n",
    "\n",
    "```\n",
    "editcap -c [chunk size] [inputfile.pcap]  [outputdir]/[prefix].pcap\n",
    "```\n",
    "\n",
    "**In the following, we fix the chunk size to 10000 Frames.**\n",
    "\n",
    "To extract pcap into a csv file:\n",
    "\n",
    "\n",
    "```\n",
    "tshark -r [file.pcap]  -T fields -e frame.number -e frame.interface_id -e frame.len -e frame.protocols -e frame.time_delta -e ip.hdr_len -e ip.len -e ip.proto -e ip.ttl -e ip.version -E aggregator=\"$\" -E separator=\";\" -E header=y\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "05a8f77f-2257-4a31-8870-692721d26603",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 1 - Verify runtime environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e8d3ff6-8b53-4c28-8a15-6f2b9fa3e656",
     "showTitle": false,
     "title": ""
    },
    "id": "pFBNMmygrImA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    # Load the autoreload extension for IPython\n",
    "    %load_ext autoreload\n",
    "    # Set the autoreload extension to reload modules every time they are imported, so that changes made to code in the src folder are reflected in the running code\n",
    "    %autoreload 2\n",
    "    %pip install scikit-learn==1.3.1\n",
    "except:\n",
    "    IN_COLAB = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce894a1e-a20c-4e27-8ee8-7baf6240767d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 2 - Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "661790e1-502b-4093-9ad2-117a2850caa5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2.1 - Function to preprocess the data\n",
    "For each packet:\n",
    "* drop columns that are completely empty\n",
    "* use onehot encoding for protocols\n",
    "* create an index with filenames\n",
    "* clean nested data EX: `34$45` -> `34`\n",
    "* fill missing value with a default value (`-1`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc1edaa0-dbf3-493b-8532-fbe9c476fc87",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def keep_columns_with_data(df):\n",
    "    return df.loc[:, df.apply(lambda x: x.isnull().sum() != df.shape[0], axis=0)]\n",
    "\n",
    "def encode_protocols(df, colname):\n",
    "    protocols_df = df[colname].str.get_dummies(sep=':')\n",
    "\n",
    "    data_with_protocols = pd.concat([df, protocols_df], axis=1)\n",
    "\n",
    "    return data_with_protocols.drop(colname, axis=1)\n",
    "\n",
    "def create_index(df):\n",
    "    df.index = df.apply(lambda x: f\"{x['file']}\", axis=1)\n",
    "    df.drop(['file', 'frame.number'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def clean_nested(df):\n",
    "    non_numeric_cols = ['ip.hdr_len', 'ip.len', 'ip.proto', 'ip.ttl', 'ip.version']\n",
    "    for col in non_numeric_cols:\n",
    "        df[col] = df[col].apply(lambda x: str(x).split('$')[0])\n",
    "    df[non_numeric_cols] = df[non_numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "    return df\n",
    "\n",
    "def fill_missing_values(df):\n",
    "    df.fillna(-1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def preprocess(df):\n",
    "    res = encode_protocols(df, 'frame.protocols')\n",
    "    res = create_index(res)\n",
    "    res = clean_nested(res)\n",
    "    res = keep_columns_with_data(res)\n",
    "    res = fill_missing_values(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3ce8e8fc-a513-4d53-bd73-c75633fe24fe",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2.2 - Function to create features\n",
    "The objective is to create a dataframe where each row is a single file. To do so, we need to aggregate the data per file. We are using `sum` to aggregate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0bfecc93-ed9b-43de-9d2c-46c3bf48a19c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    df = df.groupby(level=0).sum()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a477547-848d-4b7f-bfa5-4ce9ba25e5f1",
     "showTitle": false,
     "title": ""
    },
    "id": "7LxDnL_bY66b",
    "tags": []
   },
   "source": [
    "## 3 - Load Data\n",
    "First part is to read the data from the disk. The data has been extracted using `tshark` and stored in a CSV files `extract_active.csv` and `extract_idle.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ade523ce-e386-482f-ae3c-9b76501774e7",
     "showTitle": false,
     "title": ""
    },
    "id": "lK-CKx7kraqz"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df_active = pd.read_csv(\"https://github.com/b-yond-infinite-network/sharkfest-europe-2023-data/raw/main/packet-anomaly-detection/packet-anomaly-detection-data-active.zip\", compression='zip' ,index_col=0)\n",
    "df_idle = pd.read_csv(\"https://github.com/b-yond-infinite-network/sharkfest-europe-2023-data/raw/main/packet-anomaly-detection/packet-anomaly-detection-data-idle.zip\", compression='zip' ,index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a094da4a-ed04-40ac-99f3-9bfb9e99d9c2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_active.info()\n",
    "df_idle.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db08c046-2b6b-47bb-8b14-8d42c90c53c2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 4 - Preprocess and Create Features\n",
    "Apply `preprocessing` and `create_features` functions to both data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f16fc51-3c04-4232-9c90-a69be34a286d",
     "showTitle": false,
     "title": ""
    },
    "id": "A-tssgu2yjG2"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df_active = create_features(preprocess(df_active))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4214b81-c69e-412c-919d-63aff0173c84",
     "showTitle": false,
     "title": ""
    },
    "id": "hUQ6Qdr2ypS1"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df_idle = create_features(preprocess(df_idle))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "57a3ad66-22fe-439c-956b-87e5570fbb22",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 4.1 - drop columns primarily composed of zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0685cee5-0d55-4615-a6a6-39b7b130c9ec",
     "showTitle": false,
     "title": ""
    },
    "id": "7zPz6qCw3PCo"
   },
   "outputs": [],
   "source": [
    "# drop columns that are primarily composed of zeros \n",
    "df_idle = df_idle.loc[:,df_idle.mean().sort_values()>10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "819daaa3-bc2d-4a4e-94b0-db6bf0a57d59",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 4.2 - make sure both datasets have the same columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a62fefb-4310-408d-b9e2-07db4605f451",
     "showTitle": false,
     "title": ""
    },
    "id": "ZnMhgRFO2CkF"
   },
   "outputs": [],
   "source": [
    "# use the columns that remain for df_idle to Find common columns in both DFs \n",
    "columns = list(set(df_active.columns) & set(df_idle.columns))\n",
    "\n",
    "#only keep columns that are present in both\n",
    "df_active = df_active[columns]\n",
    "df_idle = df_idle[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a98a270-938d-46e7-9825-b2bc72c94d6a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_active.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9708e1cf-0222-438f-9feb-f859aa23b4ed",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_idle.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad2abcef-e554-4a0b-930d-6cdf01a72d78",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 5 - Model Training & results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "02a06b48-8d46-43c9-b300-c76adedb5693",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 5.1 - Create a train test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3b3787e-1d48-48d4-a96c-c72173ce1fb7",
     "showTitle": false,
     "title": ""
    },
    "id": "n8DRIT4Z262j"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import train_test_split\n",
    "pos_train, pos_test = train_test_split(df_idle,test_size=0.01)\n",
    "neg_train, neg_test = train_test_split(df_active,test_size=0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f0bd252-5f0e-4a16-b9b1-1c1d38dea338",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 5.1.1 - Create a training set \n",
    "with only idle pcap summaries (idle PCAPs will be our normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0671ea75-574f-403d-b596-36a2bc1f67e5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train = pd.concat([pos_train]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3aa4d5c-db18-4361-820d-4322e55ab8f3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 5.1.2 - Test set \n",
    "with 1% idle PCAPs and 99% active PCAPs (mostly representing abnormal cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6c38e61-cf21-43ef-84fc-561837602fce",
     "showTitle": false,
     "title": ""
    },
    "id": "Ks4I2b6k3m1F"
   },
   "outputs": [],
   "source": [
    "test = pd.concat([pos_test,neg_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7f8ae1a4-b8a4-4908-be23-1429968097cc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 5.2 PCA dimentionality reduction \n",
    "to 2 dimensions (used as a pre processor for the isolation forest in the next step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb0e3c3d-f3ff-4adc-9590-ecade98163cb",
     "showTitle": false,
     "title": ""
    },
    "id": "w5DUBkMXDSk-"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_train = pd.DataFrame(pca.fit_transform(train), columns=['PC1','PC2'])\n",
    "pca_test =  pd.DataFrame(pca.transform(test), columns=['PC1','PC2'])\n",
    "pca_train['label'] = len(train)*[1]\n",
    "pca_test['label'] = len(pos_test)*[1]+len(neg_test)*[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "color_map = {\n",
    "    1:'blue',\n",
    "    -1:'red'\n",
    "}\n",
    "\n",
    "ax = pca_train.plot.scatter(x='PC1', y='PC2',c='blue', label='Idle',alpha=0.2,figsize=(20, 10))\n",
    "pca_test[pca_test['label'] == 1].plot.scatter(x='PC1', y='PC2',c='blue', ax=ax,alpha=0.2)\n",
    "pca_test[pca_test['label'] == -1].plot.scatter(x='PC1', y='PC2',c='red', label='Active',ax=ax,alpha=0.2)\n",
    "\n",
    "plt.legend()\n",
    "plt.style.use('default')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f9453f5a-7bfb-44d5-9eb5-5962c0532f5f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 5.3 - training an Isolation Forest model\n",
    "on the data using just the idle PCAP summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a600f38-426c-44cc-8a07-cee3f140fe04",
     "showTitle": false,
     "title": ""
    },
    "id": "vF15oZkXDUs2"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import IsolationForest\n",
    "iforest = IsolationForest(n_estimators = 2, contamination = 0.4,random_state=42)\n",
    "iforest.fit(pca_train[['PC1','PC2']]) #fit the model to normal\n",
    "preds_test = iforest.predict(pca_test[['PC1','PC2']]) #predict on external data\n",
    "pca_test['preds'] = preds_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a8be7c39-821a-48e2-b325-8975cc4af801",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 5.3.1 - Results from the Isolation Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea7d0ad8-3668-41cc-b841-c650efa52d16",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bsQlPE31DXHL",
    "outputId": "0a41c73a-bba1-4224-cf6c-1ecef1329af9"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "print(classification_report(pca_test['label'],pca_test['preds']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(pca_test['label'],pca_test['preds'])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=['Active','Idle'])\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "556c82b0-1a52-4fec-a966-8915cb327099",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 5.3.2 - Plot results of isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41a81f01-1ece-45db-bc8e-bf68eab8d4a9",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZyfeZ5T6DfDK",
    "outputId": "7b11f3a9-8e4f-4100-e4a9-efcca037928e"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "ax = plt.gca()\n",
    "disp = DecisionBoundaryDisplay.from_estimator(\n",
    "    estimator=iforest,\n",
    "    X=pca_test[['PC1','PC2']],\n",
    "    response_method=\"decision_function\",\n",
    "    ax=ax\n",
    ")\n",
    "disp.ax_.set_title(\"Path length decision boundary \\nof IsolationForest\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pca_test['label'].to_list()\n",
    "plt.figure(figsize=(10,10))\n",
    "ax = plt.gca()\n",
    "disp = DecisionBoundaryDisplay.from_estimator(\n",
    "    estimator=iforest,\n",
    "    X=pca_test[['PC1','PC2']],\n",
    "    response_method=\"decision_function\",\n",
    "    ax=ax\n",
    ")\n",
    "scatter = disp.ax_.scatter(pca_test['PC1'], pca_test['PC2'],s=20, edgecolor=\"w\")\n",
    "\n",
    "disp.ax_.set_title(\"Path length decision boundary \\nof IsolationForest\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pca_test['label'].to_list()\n",
    "plt.figure(figsize=(10,10))\n",
    "ax = plt.gca()\n",
    "disp = DecisionBoundaryDisplay.from_estimator(\n",
    "    estimator=iforest,\n",
    "    X=pca_train[['PC1','PC2']],\n",
    "    response_method=\"decision_function\",\n",
    "    ax=ax\n",
    ")\n",
    "scatter = disp.ax_.scatter(pca_train['PC1'], pca_train['PC2'],s=20, edgecolor=\"w\")\n",
    "\n",
    "disp.ax_.set_title(\"Path length decision boundary \\nof IsolationForest\")\n",
    "\n",
    "\n",
    "display(figure())"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "packet-anomaly-detection",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
