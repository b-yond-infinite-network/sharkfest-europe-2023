{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0DM8COOjidJK"
   },
   "source": [
    "# PCAP Clustering\n",
    "## Data Generation\n",
    "### Introduction\n",
    "We used a (3GPP) 5G Lab to generate sample test traffic to run machine learning experiments. The 3rd Generation Partnership Project (3GPP) is a virtual organization that collects the view of seven telecommunications standard development organizations around the world. Since the development of the third generation (3G) mobile network standards, they have been spearheading the standards development effort in this arena. 5G is the technology standard defined by 3GPP from Release 15, fully specified by September 2019. Since mid 2019 numerous 5G networks have been deployed around the world and as of 4Q2023 over 1.1B subscribers are using it.\n",
    "\n",
    "One of the characteristics of 5G is the distribution of network functionality between control plane (signaling) and user plane (packet forwarding). In addition 5G uses HTTP2 protocol extensively where multiple network functions communicate with each other a common service bus. 5G adopts the recent improvement in system architecture and dictates network functions to be implemented in a containerized format. This allowed the implementation of these network functions as open source containers distributed for experimentation, testing. Some example open-source libraries include [open5gs](https://github.com/open5gs) and [UERANSIM](https://github.com/aligungr/UERANSIM).\n",
    "\n",
    "### Topology\n",
    "For testing we used the following lab topology where various network functions as well as User Equipment (UE) were implemented as containers.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/b-yond-infinite-network/sharkfest-europe-2023/main/assets/LAAS-Network-Slicing.png\"> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ECQYDyLsnN2P"
   },
   "source": [
    "### Test Traffic\n",
    "Test traffic was generated from a traffic generator, [fortio](fortio)  that allows generation of numerous types of synthetic traffic, including dns, http, tcp, udp and grpc. Fortio was deployed a traffic server and also included in the container image of the UE where fortio client is used to generate test traffic towards the fortio server.\n",
    "\n",
    "In order to make the test-bed traffic diverse, impairment tool [pumba](https://github.com/alexei-led/pumba) was used. Pumba is used to generate process, network and performance impairments. Process impairments are related to pausing, stopping, killing and removing containers. In this set-up, we didnâ€™t use these capabilities. Instead we relied on the network emulation capabilities of pumba which provides the following network impairments:\n",
    "\n",
    "* delay\n",
    "\n",
    "* loss\n",
    "\n",
    "* duplicate\n",
    "\n",
    "* corrupt\n",
    "\n",
    "* rate-limit\n",
    "\n",
    "In addition to fortio we used icmp_ping from the UE towards the fortio server to create test traffic. All traffic was captured from four Linux bridges to ensure all traffic is captured in a single pcap file corresponding to any control plane and user plane traffic.\n",
    "\n",
    "```\n",
    "$ sudo docker network list\n",
    "NETWORK ID     NAME                   DRIVER    SCOPE\n",
    "a3bb3f0b4bdc   bridge                 bridge    local\n",
    "1dbfe33d5a4f   host                   host      local\n",
    "6a5d4c99167f   laas-5gsa-docker_cp    bridge    local\n",
    "cc7d4568c741   laas-5gsa-docker_oam   bridge    local\n",
    "4dec7fb20e13   laas-5gsa-docker_sbi   bridge    local\n",
    "30dc0e1ba2f9   laas-5gsa-docker_up    bridge    local\n",
    "b84e483fa615   none                   null      local\n",
    "tshark -l -i br-6a5d4c99167f -i br-30dc0e1ba2f9 -i br-cc7d4568c741 -i br-4dec7fb20e13 -w <filename.pcap>    \n",
    "```\n",
    "Traffic generation was initiated with the following comments (following example is for tcp echo where 100 requests were sent at the rate of 1 req per sec.):\n",
    "```\n",
    "ip route add 100.0.0.2 via 10.46.0.2 dev uesimtun0\n",
    "fortio load -qps -1 -n 100 tcp://100.0.0.2:8078\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VwJLAyTjn3KM"
   },
   "source": [
    "In order to add impurity the following were applied to the user plane function (UPF) container on its eth0 interface connecting it to the fortio server.\n",
    "```\n",
    "pumba netem --duration 5m --interface eth0 delay --time 300 --jitter 30 --correlation 50 --distribution normal core_upf\n",
    "pumba netem --duration 5m --interface eth0 loss --percent 50 --correlation 50 core_upf\n",
    "pumba netem --duration 5m --interface eth0 rate --rate 10kbit core_upf\n",
    "pumba netem --duration 5m --interface eth0 duplicate --percent 50 --correlation 50 core_upf\n",
    "pumba netem --duration 5m --interface eth0 corrupt --percent 50 --correlation 50 core_upf\n",
    "```\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/b-yond-infinite-network/sharkfest-europe-2023/main/assets/5g-laas-setup.png\" width=\"70%\">\n",
    "\n",
    "\n",
    "\n",
    "To extract pcap into a csv file:\n",
    "\n",
    "\n",
    "```\n",
    "tshark -r [file.pcap]  -T fields -e frame.number -e frame.interface_id -e frame.len -e frame.protocols -e frame.time_delta -e ip.hdr_len -e ip.len -e ip.proto -e ip.ttl -e ip.version -E aggregator=\"$\" -E separator=\";\" -E header=y > data.csv\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ai_CGEl3opN3"
   },
   "source": [
    "## Objectives\n",
    "In the following procedure we will show how to apply an unsupervised approach to cluster pcaps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JkE7wl73pUhe"
   },
   "source": [
    "### Verify runtime environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    # Load the autoreload extension for IPython\n",
    "    %load_ext autoreload\n",
    "    # Set the autoreload extension to reload modules every time they are imported, so that changes made to code in the src folder are reflected in the running code\n",
    "    %autoreload 2\n",
    "    %pip install scikit-learn==1.3.1\n",
    "except:\n",
    "    IN_COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbF-AaFoo8l8"
   },
   "source": [
    "### Basic installations and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ET-H7HyPpFWd"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r7RW7uuApfW5"
   },
   "source": [
    "### Function to preprocess the data\n",
    "For each paquet:\n",
    "* use onehot encoding for protocols\n",
    "* create an index with filenames\n",
    "* clean nested data EX: `34$45` -> `34`\n",
    "* fill missing value with a default value (`-1`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s0P8MhraeUFI"
   },
   "outputs": [],
   "source": [
    "def encode_protocols(df, colname):\n",
    "    protocols_df = df[colname].str.get_dummies(sep=':')\n",
    "\n",
    "    data_with_protocols = pd.concat([df, protocols_df], axis=1)\n",
    "\n",
    "    return data_with_protocols.drop(colname, axis=1)\n",
    "\n",
    "\n",
    "def create_index(df):\n",
    "    df.index = df.apply(lambda x: f\"{x['file']}\", axis=1)\n",
    "    df.drop(['file', 'frame.number'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def clean_nested(df):\n",
    "    non_numeric_cols = ['ip.hdr_len', 'ip.len', 'ip.proto', 'ip.ttl', 'ip.version']\n",
    "    for col in non_numeric_cols:\n",
    "        df[col] = df[col].apply(lambda x: str(x).split('$')[0])\n",
    "    df[non_numeric_cols] = df[non_numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "    return df\n",
    "\n",
    "def fill_missing_values(df):\n",
    "    df.fillna(-1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def preprocess(df):\n",
    "    res = encode_protocols(df, 'frame.protocols')\n",
    "    res = create_index(res)\n",
    "    res = clean_nested(res)\n",
    "    res = fill_missing_values(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j4pSSGswqIet"
   },
   "source": [
    "### Function to create features\n",
    "The objective is to create a dataframe where each row is a single file. To do so, we need to aggregate the data per file. We are using `mean` to aggregate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-j08LRmNfCNN"
   },
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    df = df.groupby(level=0).mean()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HurV8adjqrnQ"
   },
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7xrncCGWqoUz"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "data_path = \"https://raw.githubusercontent.com/b-yond-infinite-network/sharkfest-europe-2023-data/main/network-traces-clustering/data.csv\"\n",
    "df = pd.read_csv(data_path,index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "UHPWXgethxbU",
    "outputId": "05317ed7-5d02-4944-c6b0-97228774b2e3"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H6ZSSO49q0Kd"
   },
   "source": [
    "### Apply preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cl0Gu3-ghyWj"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df = preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "DRvDFSUOh2Jr",
    "outputId": "16c14265-ed73-4de0-e7a6-4e15e4ce59ca"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6IvBfGTsq7uy"
   },
   "source": [
    "### Create the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ppahjviAj1Aq"
   },
   "outputs": [],
   "source": [
    "df = create_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "NXDymGF5lcTl",
    "outputId": "d89a11eb-0857-4e40-e89c-8776e62fc03a"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W_AOCdbZrNQw"
   },
   "source": [
    "### Standardize the data to avoid the scale effect when computing the distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2paGY8MpiNZ8"
   },
   "outputs": [],
   "source": [
    "# Initializing the scaler\n",
    "scaler = MinMaxScaler()\n",
    "# Fitting and transforming the data\n",
    "scaled_data = scaler.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-nf3YPgMrgAi",
    "outputId": "3500f2bc-552e-4b99-b138-2ef221b4952b"
   },
   "outputs": [],
   "source": [
    "scaled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CVblSbxurcj2"
   },
   "source": [
    "### Create a hierarchical clustering\n",
    "\n",
    "For more details on the different parameter of `linkage`, check [docs here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QoFkm-caiDuU"
   },
   "outputs": [],
   "source": [
    "Z = linkage(scaled_data, method='average', metric='cityblock')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sGYUnyLlsJlk"
   },
   "source": [
    "### Ploting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 563
    },
    "id": "RuzW4yItiLo_",
    "outputId": "8926b40c-e288-48af-f8dd-23ecd1bac898"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "dendrogram(Z, labels= df.index.astype(str).tolist(), leaf_rotation=90, leaf_font_size=15)\n",
    "plt.title(\"Hierarchical Clustering Dendrogram\")\n",
    "plt.xlabel(\"PCAP Files\")\n",
    "plt.ylabel(\"Manhatten Distance\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Am7NNATvu0XN"
   },
   "source": [
    "### Extract clusters\n",
    "\n",
    "For more details on the different parameters for `fcluster` check [docs here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.fcluster.html#scipy.cluster.hierarchy.fcluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JGwUYmZWtCV7"
   },
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import fcluster\n",
    "groups = fcluster(Z, t= 6, criterion='maxclust')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n-lF_DxqtQUP",
    "outputId": "90667ef5-d121-404d-b05a-8879ce80b7fc"
   },
   "outputs": [],
   "source": [
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "peD5ul6otfrC"
   },
   "outputs": [],
   "source": [
    "df['groups'] = groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eLQaluyvtlYy",
    "outputId": "7139cdd2-ea02-4482-eab3-895adba4e605"
   },
   "outputs": [],
   "source": [
    "df[df['groups'] == 1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tw9NNn7rttXD",
    "outputId": "ca1cf294-fa62-4cad-a1de-1feaf83d3e95"
   },
   "outputs": [],
   "source": [
    "df[df['groups'] == 2].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2AUrHw0kt46D",
    "outputId": "46767c61-ac04-4f25-f063-b45dc2423b89"
   },
   "outputs": [],
   "source": [
    "df[df['groups'] == 3].index"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
